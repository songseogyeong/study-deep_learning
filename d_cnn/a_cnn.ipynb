{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368ad91a-fe06-4d65-b4bf-967a91e25235",
   "metadata": {},
   "source": [
    "### CNN (Convolutional Neural Network), 합성곱 신경망\n",
    "- 실제 이미지 데이터는 분류 대상이 이미지에서 고정된 위치에 있지 않은 경우가 대부분이다.\n",
    "- 실제 이미지 데이터를 분류하기 위해서는, 이미지의 각 feature들을 그대로 학습하는 것이 아닌, CNN으로 패턴을 인식한 뒤 학습해야 한다.  \n",
    "<sub>* CNN은 input 전 학습하며, 은닉층이다.</sub>\n",
    "\n",
    "<div style=\"display: flex; width:70%; margin-bottom: 30px;\">\n",
    "    <div>\n",
    "        <img src=\"./images/dogs01.png\" width=\"500\" style=\"margin-left: 20px\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"./images/dogs02.png\" width=\"720\" style=\"margin-left: 80px\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "- 이미지의 크기가 커질 수록 굉장히 많은 Weight가 필요하기 때문에 분류기에 바로 넣지 않고, 이를 사전에 추출 및 축소해야 한다.\n",
    "- CNN은 인간의 시신경 구조를 모방한 기술로서, 이미지의 패턴을 찾을 때 사용한다.\n",
    "- Feature Extraction을 통해 각 단계를 거치면서, 함축된 이미지 조각으로 분리되고 각 이미지 조각을 통해 이미지의 패턴을 인식한다.  \n",
    "<sub>* 오른쪽 이미지는 학습 시 전체 픽셀을 진행할 필요가 없어 패턴을 분석시켜 진행한다.<br>\n",
    "눈, 코, 입 등 부분만 가져와 줄여나가면 왼쪽 이미지처럼 이미지가 모이는데 그걸 input으로 넣어 사용한다.</sub>\n",
    "\n",
    "<img src=\"./images/cnn01.png\" width=\"700\" style=\"margin-left: 0; margin-bottom: 20px\">\n",
    "\n",
    "- CNN은 분류하기에 적합한 최적의 featrue를 추출하고, 최적의 feature를 추출하기 위한 최적의 Weight와 Filter를 계산한다.\n",
    "\n",
    "<img src=\"./images/cnn02.png\" width=\"500\" style=\"margin-left: 50px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeebb50a-b9ce-4ec6-bed1-40f6147167b1",
   "metadata": {},
   "source": [
    "#### Filter\n",
    "- 보통 정방 행렬로 구성되어 있고, 원본 이미지에 슬라이딩 윈도우 알고리즘을 사용하여 순차적으로 새로운 픽셀값을 만들면서 적용한다.\n",
    "- 사용자가 목적에 맞는 특정 필터를 만들거나 기존에 설계된 다양한 필터를 선택하여 이미지에 적용한다.  \n",
    "  하지만, CNN은 최적의 필드값을 학습하여 스스로 최적화한다.\n",
    "\n",
    "<img src=\"./images/filter.gif\" width=\"400\" style=\"margin-left: 0px; margin-top: -30px; margin-bottom: -50px\">\n",
    "<img src=\"./images/filter.png\" width=\"500\" style=\"margin-left: 0;\">\n",
    "\n",
    "- 필터 하나 당, 이미지의 채널 수 만큼 Kernel이 존재하고, 각 채널에 할당된 필터의 커널을 적용하여 출력 이미지를 생성한다.\n",
    "- 출력 feature map(=활성화 함수)의 개수는 필터의 개수와 동일하다.  \n",
    "<sub>*내가 사용하는 필터의 개수는 아웃풋의 개수이다.<br>\n",
    "*필터의 개수는 bias(편향)으로 들어간다.<br>\n",
    "*커널의 크기는 커널만의 사이즈가 있다.<br>\n",
    "*필터는 항상 채널의 수와 동일하다.<br>\n",
    "*epoch=필터, batch=채널</sub>\n",
    "\n",
    "<img src=\"./images/filter_channel.gif\" width=\"500\">\n",
    "\n",
    "#### Kernel\n",
    "- filter 안에 1 ~ n 개의 커널이 존재한다. 커널의 개수는 반드시 이미지의 채널 수와 동일해야 한다.\n",
    "- Kernel Size는 가로 X 세로를 의미하며, 가로와 세로는 서로 다를 수 있지만 보통은 일치시킨다.\n",
    "- Kernel Size가 크면 클 수록 입력 이미지에서 더 많은 feature 정보를 가져올 수 있지만,  \n",
    "  큰 사이즈의 Kernel로 Convolution Backbone을 할 경우 훨씬 더 많은 연산량과 파라미터가 필요하다.  \n",
    "<sub>*채널은 tuple 또는 정수로 전달이 가능한데, 정방이면 정수를 사용하고 아니라면 tuple을 사용한다.</sub>\n",
    "\n",
    "<img src=\"./images/kernel.gif\" width=\"500\">\n",
    "\n",
    "#### Stride\n",
    "- 입력 이미지에 Convolution Filter를 적용할 때 Sliding Window가 이동하는 간격을 의미한다.\n",
    "- 기본 stride는 1이지만, 2를 적용하면 입력 feature map 대비 출력 feature map의 크기가 절반정도 줄어든다.\n",
    "- stride를 키우면 feature 정보를 손실할 가능성이 높아지지만,  \n",
    "  오히려 불필요한 특성을 제거하는 효과를 가져올 수 있고 Convolution 연산 속도를 향상 시킨다.  \n",
    "<sub>*크기를 줄이고 싶다면, Stride를 높이면 된다.</sub>\n",
    "\n",
    "<div style=\"display: flex; width:70%; margin-top: 10px;\">\n",
    "    <div>\n",
    "        <img src=\"./images/stride01.gif\" width=\"600\" style=\"margin-left: 0; margin-top: 0\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"./images/stride02.gif\" width=\"600\" style=\"margin-left: 50px\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "#### Padding\n",
    "- Filter를 적용하여 Convolution 수행 시 출력 feature map이 입력 feature map 대비 계속해서 작아지는 것을 막기 위해 사용한다.\n",
    "- Filter 적용 전, 입력 feature map의 상하좌우 끝에 각각 열과 행을 추가한 뒤, 0으로 채워서 크기를 증가시킨다.\n",
    "- 출력 이미지의 크기를 입력 이미지의 크기와 동일하게 유지하기 위해서 직접 계산할 필요 없이 \"same\"이라는 값을 통해 입력 이미지의 크기와 동일하게 맞출 수 있다.\n",
    "\n",
    "<img src=\"./images/padding.gif\" width=\"600\" style=\"margin-left: 0\">\n",
    "\n",
    "#### Pooling\n",
    "- Convolution이 적용된 feature map의 일정 영역별로 하나의 값을 추출하여 feature map의 사이즈를 줄인다.\n",
    "- 보통은 Convolution -> Relu activation -> Pooling 순서로 적용한다.\n",
    "- 비슷한 feature들이 서로 다른 이미지에서 위치가 달라지면서 다르게 해석되는 현상을 중화시킬 수 있고,  \n",
    "  feature map의 크기가 줄어들기 때문에, 연산 성능이 향상된다.\n",
    "- Max Pooling과 Average Pooling이 있으며, Max Pooling은 중요도가 가장 높은 feature를 추출하고, Average Pooling은 전체를 버무려서 추출한다.  \n",
    "<sub>*Max Pooling으로는 위치만 달라져있는 달 위치 등을 찾는데 좋다.<br>\n",
    "*예를들어, 국기를 Average를 사용하여 평균을 내버리면, 빨강 + 파랑의 평균값 보라색으로 결론을 내기 때문에 문제가 발생할 수 있다.<br>\n",
    "*실전에서는 weight 값의 중요에 따라 결정된다.<br>\n",
    "*Max와 Average를 비교했을 때, 성능이 Max가 더 좋아 Max를 더 많이 사용하는데, 상황에 따라 Average를 사용한다.<br>\n",
    "하지만, Max와 Average보다는 Stride를 더 많이 사용한다.</sub>\n",
    "\n",
    "<img src=\"./images/pooling.gif\" width=\"450\" style=\"margin-top: 20px; margin-bottom: 30px\">\n",
    "\n",
    "맥스 풀링(최대값) 에버리지 풀링(평균)  \n",
    "맥스 풀링 > 달이미지 위치만 달라져있는 달위치 찾는데 좋음  \n",
    "성능이 맥스가 더 좋고 보통 맥스를 쓰고 상황에 따라서 에버리지를 사용함\n",
    "근데 일단 스트라이드를 사용함\n",
    "\n",
    "국기예시\n",
    "만약 에버리지로 평균을 내버리면\n",
    "국기 색이 빨파면 중간 값 보라색을 내버림\n",
    "그럼 문제가 있ㅇ므\n",
    "\n",
    "일단 예시 이고 실전은 웨이트 값의 중요도에 따라 결정됨\n",
    "\n",
    "맥스가 릿지 느낌 최대 말고 다 삭제\n",
    "에버리지가 라쏘느낌 평균...\n",
    "\n",
    "\n",
    "#### 🚩정리\n",
    "- Stride를 증가시키는 것과 Pooling을 적용하는 것은 출력 feature map의 크기를 줄이는 데 사용하는 것이다.\n",
    "- Convolution 연산을 진행하면서, feature map의 크기를 줄이면, 위치 변화에 따른 feature의 영향도도 줄어들기 때문에 과적합을 방지할 수 있는 장점이 있다.\n",
    "- Pooling의 경우 특정 위치의 feature 값이 손실되는 이슈 등으로 인하여 최근 Advanced CNN에서는 많이 사용되지 않는다.\n",
    "- Classifier에서는 Fully Connected Layer의 지나친 연결로 인해 많은 파라미터가 생성되므로 오히려 과적합이 발생할 수 있다.\n",
    "\n",
    "<img src=\"./images/cnn03.png\" width=\"850px\">\n",
    "\n",
    "- Dropout을 사용해서 Layer간 연결을 줄일 수 있으며 과적합을 방지할 수 있다.\n",
    "  \n",
    "<img src=\"./images/dropout.png\" width=\"850px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a6e4c-7574-4ee9-9ea6-ad52ee1605df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TIP!\n",
    "채널 개수 보는 법  \n",
    "(28, 28, 1) -> 뒤에 1이 채널이자 채널의 개수가 된다.\n",
    "(1, 28, 28, 3) -> 맨 앞 1이 채널 개수, 뒤 3이 채널이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1282af6-b78d-42c9-b391-32d9935ee854",
   "metadata": {},
   "source": [
    "--\\\n",
    "\n",
    "\n",
    "\n",
    "--\n",
    "\n",
    "슬라이딩 윈도우 \n",
    "\n",
    "--\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "정리\n",
    "필터는 출력 피처맵의 개수랑 똑같고\n",
    "커널 개수랑 채널 개수는 같음!!\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "(28, 28, 1)\n",
    "두;ㅣ에 1이 채널이자 채널 개수가 됨\n",
    "(1, 28, 28, 3)\n",
    "하면 채널 한개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae577b10-441f-49a5-bfaa-5b0d28b6782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, 14, 14, 4), dtype=float32, sparse=False, name=keras_tensor_1>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "INPUT_SIZE = 28\n",
    "\n",
    "input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 1))\n",
    "x = Conv2D(filters=4, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31ca6642-f63e-40d4-b4bc-5198b2681e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, 3, 3, 4), dtype=float32, sparse=False, name=keras_tensor_9>\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 32\n",
    "\n",
    "input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 1))\n",
    "x = Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\n",
    "x = MaxPooling2D(2)(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b346eb26-c272-4df7-8073-e9f369420b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,816</span> (73.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,816\u001b[0m (73.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,816</span> (73.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,816\u001b[0m (73.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INPUT_SIZE = 32\n",
    "\n",
    "input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 1))\n",
    "\n",
    "# input = 1\n",
    "# kernel = 3 * 3 = 9\n",
    "# filter = 32\n",
    "# 288 + 32 = 320 (파라미터 수)\n",
    "x = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\n",
    "\n",
    "# input = 32\n",
    "# kernel = 3 * 3 = 9\n",
    "# filter = 64\n",
    "# 18432‬ + 64 = 18496\n",
    "x = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "\n",
    "# 최대값 추출하는 거라 파라미터 값이 나오지 않음\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "048880a1-53f6-4d77-a588-bff5d8c12953",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10816</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">540,850</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10816\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │         \u001b[38;5;34m540,850\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m510\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">560,176</span> (2.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m560,176\u001b[0m (2.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">560,176</span> (2.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m560,176\u001b[0m (2.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
    "# ┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
    "# ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
    "# │ input_layer_12 (InputLayer)          │ (None, 28, 28, 1)           │               0 │\n",
    "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "# │ conv2d_22 (Conv2D)                   │ (None, 28, 28, 32)          │             320 │\n",
    "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "# │ conv2d_23 (Conv2D)                   │ (None, 26, 26, 64)          │          18,496 │\n",
    "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "# │ max_pooling2d_11 (MaxPooling2D)      │ (None, 13, 13, 64)          │               0 │\n",
    "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "# │ flatten_9 (Flatten)                  │ (None, 10816)               │               0 │\n",
    "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "# │ dense_18 (Dense)                     │ (None, 50)                  │         540,850 │\n",
    "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "# │ dense_19 (Dense)                     │ (None, 10)                  │             510 │\n",
    "# └──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "INPUT_SIZE = 28\n",
    "\n",
    "input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 1))\n",
    "\n",
    "# input = 1\n",
    "# kernel = 3 * 3 = 9\n",
    "# filter = 32\n",
    "# 288 + 32 = 320\n",
    "x = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\n",
    "\n",
    "# input = 32\n",
    "# kernel = 3 * 3 = 9\n",
    "# filter = 64\n",
    "# 18432‬ + 64 = 18496\n",
    "x = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da26a575-54bf-458f-bb62-16ef929e19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "플랫튼 하고 드롭아웃하고\n",
    "레이트 몇 퍼센트 비활성화할건지(날리는게 아님 파람수는 동일함)\n",
    "\n",
    "에포크 수는 그대로 두되 얼리 스타핑을 사용...\n",
    "임의로 멈추면 안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794b1714-da80-43ce-a533-7d29d5d51780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def get_preprocessed_data(images, targets):\n",
    "    images = np.array(images / 255.0, dtype=np.float32)\n",
    "    targets = np.array(targets, dtype=np.float32)\n",
    "\n",
    "    return images, targets\n",
    "\n",
    "def get_preprocessed_ohe(images, targets):\n",
    "    images, targets = get_preprocessed_data(images, targets)\n",
    "    oh_targets = to_categorical(targets)\n",
    "\n",
    "    return images, oh_targets\n",
    "\n",
    "def get_train_valid_test(train_images, train_targets, test_images, test_targets, validation_size=0.2, random_state=124):\n",
    "    train_images, train_oh_targets = get_preprocessed_ohe(train_images, train_targets)\n",
    "    test_images, test_oh_targets = get_preprocessed_ohe(test_images, test_targets)\n",
    "\n",
    "    train_images, validation_images, train_oh_targets, validation_oh_targets = \\\n",
    "    train_test_split(train_images, train_oh_targets, stratify=train_oh_targets, test_size=validation_size, random_state=random_state)\n",
    "\n",
    "    return (train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d81c7d-3019-45c5-b693-64315f888551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(train_images, train_targets), (test_images, test_targets) = fashion_mnist.load_data()\n",
    "\n",
    "(train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets) = \\\n",
    "get_train_valid_test(train_images, train_targets, test_images, test_targets)\n",
    "\n",
    "print(train_images.shape, train_oh_targets.shape)\n",
    "print(validation_images.shape, validation_oh_targets.shape)\n",
    "print(test_images.shape, test_oh_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d24825-4f54-4669-9463-ed898791fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(0.001), loss=CategoricalCrossentropy(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5e66f2-86d2-417d-ba78-f55a8759c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=train_images, \n",
    "                    y=train_oh_targets, \n",
    "                    batch_size=64, \n",
    "                    epochs=20, \n",
    "                    validation_data=(validation_images, validation_oh_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a614366-525b-4f8e-a5d6-a13037aa0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_history(history):\n",
    "    plt.plot(history.history['acc'], label='train')\n",
    "    plt.plot(history.history['val_acc'], label='validation')\n",
    "    plt.legend()\n",
    "    \n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc167f86-aef4-46c7-b096-9dce793a08ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 세트로 모델 성능 검증\n",
    "model.evaluate(test_images, test_oh_targets, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db1c748-8ca3-4299-b443-5b1ab0c8c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
    "# ┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
    "# ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
    "# │ input_layer_12 (InputLayer)          │ (None, 28, 28, 1)           │               0 │\n",
    "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "# │ conv2d_22 (Conv2D)                   │ (None, 28, 28, 32)          │             320 │\n",
    "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "# │ conv2d_23 (Conv2D)                   │ (None, 26, 26, 64)          │          18,496 │\n",
    "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "# │ max_pooling2d_11 (MaxPooling2D)      │ (None, 13, 13, 64)          │               0 │\n",
    "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "# │ flatten_9 (Flatten)                  │ (None, 10816)               │               0 │\n",
    "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "# │ dense_18 (Dense)                     │ (None, 50)                  │         540,850 │\n",
    "# ├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
    "# │ dense_19 (Dense)                     │ (None, 10)                  │             510 │\n",
    "# └──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "INPUT_SIZE = 28\n",
    "\n",
    "input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 1))\n",
    "\n",
    "# input = 1\n",
    "# kernel = 3 * 3 = 9\n",
    "# filter = 32\n",
    "# 288 + 32 = 320\n",
    "x = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\n",
    "\n",
    "# input = 32\n",
    "# kernel = 3 * 3 = 9\n",
    "# filter = 64\n",
    "# 18432‬ + 64 = 18496\n",
    "x = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "\n",
    "x = MaxPooling2D(2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d4454-c4a5-429b-a9f7-95d0bd667e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(0.001), loss=CategoricalCrossentropy(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7997eb-3200-4efa-b1b5-307ae035c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=train_images, \n",
    "                    y=train_oh_targets, \n",
    "                    batch_size=64, \n",
    "                    epochs=20, \n",
    "                    validation_data=(validation_images, validation_oh_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e43f1-1a92-4f9f-9eb9-3857fe04094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_history(history):\n",
    "    plt.plot(history.history['acc'], label='train')\n",
    "    plt.plot(history.history['val_acc'], label='validation')\n",
    "    plt.legend()\n",
    "    \n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad9952-52b1-4de5-8f14-00a544c9b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 세트로 모델 성능 검증\n",
    "model.evaluate(test_images, test_oh_targets, batch_size=256, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
