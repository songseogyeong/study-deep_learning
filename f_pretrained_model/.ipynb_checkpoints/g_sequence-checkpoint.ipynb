{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae781c2-0156-4404-89d0-1c55c524f4c4",
   "metadata": {},
   "source": [
    "### Sequence\n",
    "동물 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8842a85-78cb-4611-9b2a-20ae13ce1938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26179 images belonging to 10 classes.\n",
      "{'butterfly': 0, 'cat': 1, 'chicken': 2, 'cow': 3, 'dog': 4, 'elephant': 5, 'horse': 6, 'sheep': 7, 'spider': 8, 'squirrel': 9}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "root = './datasets/animals/original/'\n",
    "\n",
    "idg = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator = idg.flow_from_directory(root, target_size=(64, 64), batch_size=32, class_mode='categorical')\n",
    "print(generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c83520e-7156-4799-bc43-6405a9bfcb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'butterfly',\n",
       " 1: 'cat',\n",
       " 2: 'chicken',\n",
       " 3: 'cow',\n",
       " 4: 'dog',\n",
       " 5: 'elephant',\n",
       " 6: 'horse',\n",
       " 7: 'sheep',\n",
       " 8: 'spider',\n",
       " 9: 'squirrel'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_name = {v: k for k, v in generator.class_indices.items()}\n",
    "target_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9075e3ad-8014-4d30-a75d-f483559bd270",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = []\n",
    "for target in generator.classes:\n",
    "    target_names.append(target_name[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9625888-c379-4aac-93f0-438ec523ca37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_paths</th>\n",
       "      <th>target_names</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./datasets/animals/original/butterfly/butterfl...</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./datasets/animals/original/butterfly/butterfl...</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./datasets/animals/original/butterfly/butterfl...</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./datasets/animals/original/butterfly/butterfl...</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./datasets/animals/original/butterfly/butterfl...</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26174</th>\n",
       "      <td>./datasets/animals/original/squirrel/squirrel9...</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26175</th>\n",
       "      <td>./datasets/animals/original/squirrel/squirrel9...</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26176</th>\n",
       "      <td>./datasets/animals/original/squirrel/squirrel9...</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26177</th>\n",
       "      <td>./datasets/animals/original/squirrel/squirrel9...</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26178</th>\n",
       "      <td>./datasets/animals/original/squirrel/squirrel9...</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26179 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_paths target_names  targets\n",
       "0      ./datasets/animals/original/butterfly/butterfl...    butterfly        0\n",
       "1      ./datasets/animals/original/butterfly/butterfl...    butterfly        0\n",
       "2      ./datasets/animals/original/butterfly/butterfl...    butterfly        0\n",
       "3      ./datasets/animals/original/butterfly/butterfl...    butterfly        0\n",
       "4      ./datasets/animals/original/butterfly/butterfl...    butterfly        0\n",
       "...                                                  ...          ...      ...\n",
       "26174  ./datasets/animals/original/squirrel/squirrel9...     squirrel        9\n",
       "26175  ./datasets/animals/original/squirrel/squirrel9...     squirrel        9\n",
       "26176  ./datasets/animals/original/squirrel/squirrel9...     squirrel        9\n",
       "26177  ./datasets/animals/original/squirrel/squirrel9...     squirrel        9\n",
       "26178  ./datasets/animals/original/squirrel/squirrel9...     squirrel        9\n",
       "\n",
       "[26179 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "animal_df = pd.DataFrame({'file_paths': generator.filepaths, 'target_names': target_names, 'targets': generator.classes})\n",
    "animal_df.file_paths = animal_df.file_paths.apply(lambda file_path: file_path.replace('\\\\', '/'))\n",
    "animal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44defb0b-9748-41fb-b3ca-eb4e62eaee4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets\n",
      "4    3890\n",
      "8    3857\n",
      "2    2478\n",
      "6    2098\n",
      "0    1690\n",
      "3    1493\n",
      "9    1490\n",
      "7    1456\n",
      "1    1334\n",
      "5    1157\n",
      "Name: count, dtype: int64\n",
      "targets\n",
      "4    973\n",
      "8    964\n",
      "2    620\n",
      "6    525\n",
      "0    422\n",
      "3    373\n",
      "9    372\n",
      "7    364\n",
      "1    334\n",
      "5    289\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, test_images, train_targets, test_targets = \\\n",
    "train_test_split(animal_df.file_paths, \n",
    "                 animal_df.targets, \n",
    "                 stratify=animal_df.targets, \n",
    "                 test_size=0.2, random_state=124)\n",
    "\n",
    "print(train_targets.value_counts())\n",
    "print(test_targets.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "923ec394-622a-4507-ad5b-0ce684bf11b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets\n",
      "4    3112\n",
      "8    3086\n",
      "2    1982\n",
      "6    1678\n",
      "0    1352\n",
      "3    1194\n",
      "9    1192\n",
      "7    1165\n",
      "1    1067\n",
      "5     926\n",
      "Name: count, dtype: int64\n",
      "targets\n",
      "4    778\n",
      "8    771\n",
      "2    496\n",
      "6    420\n",
      "0    338\n",
      "3    299\n",
      "9    298\n",
      "7    291\n",
      "1    267\n",
      "5    231\n",
      "Name: count, dtype: int64\n",
      "targets\n",
      "4    973\n",
      "8    964\n",
      "2    620\n",
      "6    525\n",
      "0    422\n",
      "3    373\n",
      "9    372\n",
      "7    364\n",
      "1    334\n",
      "5    289\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, validation_images, train_targets, validation_targets = \\\n",
    "train_test_split(train_images, \n",
    "                 train_targets, \n",
    "                 stratify=train_targets, \n",
    "                 test_size=0.2, random_state=124)\n",
    "\n",
    "print(train_targets.value_counts())\n",
    "print(validation_targets.value_counts())\n",
    "print(test_targets.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d1ede6-32b1-4d13-9541-321071e8fd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16754, 3)\n",
      "(4189, 3)\n",
      "(5236, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df = animal_df.iloc[train_images.index].reset_index(drop=True)\n",
    "validation_df = animal_df.iloc[validation_images.index].reset_index(drop=True)\n",
    "test_df = animal_df.iloc[test_images.index].reset_index(drop=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(validation_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e218b7-5d9b-45bd-8d54-be385539f7ea",
   "metadata": {},
   "source": [
    "시퀀스 api는 상속 받아서 내가 재저응 ㅣ\n",
    "데이터세트 객체를"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8394032f-6fbb-49fd-94e2-8d76074c200c",
   "metadata": {},
   "source": [
    "#### Step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "877bbc16-680b-4869-bf58-e2993b9e9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "class Dataset(Sequence):\n",
    "    # 어그먼 테이션 객체를 전달\n",
    "    def __init__(self, file_paths, targets, batch_size=BATCH_SIZE, aug=None, shuffle=False):\n",
    "        self.file_paths = file_paths\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.aug = aug\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        if self.shuffle:\n",
    "            # 에포크 종료 시, 객체 생성 및 데이터 섞기\n",
    "            # 이거 하면 메모리 이슈가 발생함 그래서 직접 해제해야 함\n",
    "            # 에포크 하나 끝나자마자 실행되는 함수\n",
    "            self.on_epoch_end()\n",
    "\n",
    "# 한번 에포크당\n",
    "# 한번새로우 ㄴ데이터 세트가 만들어짐\n",
    "\n",
    "# 생성자에서 셔플에서 이프분에서 새로운 객체 만들어짐\n",
    "\n",
    "    # __len__()는 전체 데이터 건수에서 batch_size 단위로 나눈 데이터 수\n",
    "    # 하나의 배치 사이즈에 필요한 데이터 개수를 리턴해줘야함\n",
    "    # 하나의 데이터 세트에 필요한 데이터 개수\n",
    "    def __len__(self):\n",
    "        # 예를 들어, 1000개의 데이터를 30 batch_size로 설정하면, 1 batch 당 33.33...개이다.\n",
    "        # 이때, 소수점은 무조건 올려서 33 + 1 = 34개로 설정한다. (ceil 사용하여 올리기)\n",
    "        return int(np.ceil(len(self.targets) / self.batch_size))\n",
    "\n",
    "    # batch_size 단위로 이미지 배열과 타겟 데이터들을 가져온 뒤 변환한 값을 리턴한다. (preprocessing)\n",
    "    # index: 몇번째 배치인지 인덱스로 나타냄\n",
    "    def __getitem__(self, index):\n",
    "        # 시작, 끝 인덱스를 정확하게 가져올 수 있음\n",
    "        # 배치사이즈 60개라 가정 60:120하면 120은 안가져옴\n",
    "        file_paths_batch = self.file_paths[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        targets_batch = self.targets[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "\n",
    "        # 배치사이즈, 위드, 하이트, 채널 (튜플로 만들어줘야댐)\n",
    "        results_batch = np.zeros((file_paths_batch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "        # 데이터 수만큼 반복\n",
    "        for i in range(file_paths_batch.shape[0]):\n",
    "            # 이미지 가져오기\n",
    "            image = cv2.cvtColor(cv2.imread(file_paths_batch[i]), cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "            # 어그먼테이션 있으면 어그먼 테이션 적용\n",
    "            if self.aug is not None:\n",
    "                self.sug(image=image)['image']\n",
    "\n",
    "            results_batch[i] = image\n",
    "\n",
    "        return results_batch, targets_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            # 이걸 먼저 하고 getitem을 하기 때뭉네 result로 안 넣고 file_paths로 넣음\n",
    "            # 그럼 get_items에는 이미 셔플이 되어있음\n",
    "            self.file_paths, self.targets = shuffle(self.file_paths, self.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15670836-e0e7-4596-a9bf-f90f1730abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "train_file_paths = train_df['file_paths'].values\n",
    "train_targets = train_df['targets'].values\n",
    "\n",
    "aug = A.Compose([\n",
    "    A.ShiftScaleRotate(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0, p=0.5)\n",
    "])\n",
    "\n",
    "dataset = Dataset(train_file_paths, train_targets, batch_size=BATCH_SIZE, aug=aug, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade5e22-d13b-4295-a234-e9225c68be22",
   "metadata": {},
   "source": [
    "#### Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907325e-ea3e-4b35-95ae-66ec9db4b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "class Dataset(Sequence):\n",
    "    # 어그먼 테이션 객체를 전달\n",
    "    def __init__(self, file_paths, targets, batch_size=BATCH_SIZE, aug=None, preprocess=None, shuffle=False):\n",
    "        self.file_paths = file_paths\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.aug = aug\n",
    "        self.preprocess = preprocess\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        if self.shuffle:\n",
    "            # 에포크 종료 시, 객체 생성 및 데이터 섞기\n",
    "            # 이거 하면 메모리 이슈가 발생함 그래서 직접 해제해야 함\n",
    "            # 에포크 하나 끝나자마자 실행되는 함수\n",
    "            self.on_epoch_end()\n",
    "\n",
    "# 한번 에포크당\n",
    "# 한번새로우 ㄴ데이터 세트가 만들어짐\n",
    "\n",
    "# 생성자에서 셔플에서 이프분에서 새로운 객체 만들어짐\n",
    "\n",
    "    # __len__()는 전체 데이터 건수에서 batch_size 단위로 나눈 데이터 수\n",
    "    # 하나의 배치 사이즈에 필요한 데이터 개수를 리턴해줘야함\n",
    "    # 하나의 데이터 세트에 필요한 데이터 개수\n",
    "    def __len__(self):\n",
    "        # 예를 들어, 1000개의 데이터를 30 batch_size로 설정하면, 1 batch 당 33.33...개이다.\n",
    "        # 이때, 소수점은 무조건 올려서 33 + 1 = 34개로 설정한다. (ceil 사용하여 올리기)\n",
    "        return int(np.ceil(len(self.targets) / self.batch_size))\n",
    "\n",
    "    # batch_size 단위로 이미지 배열과 타겟 데이터들을 가져온 뒤 변환한 값을 리턴한다. (preprocessing)\n",
    "    # index: 몇번째 배치인지 인덱스로 나타냄\n",
    "    def __getitem__(self, index):\n",
    "        # 시작, 끝 인덱스를 정확하게 가져올 수 있음\n",
    "        # 배치사이즈 60개라 가정 60:120하면 120은 안가져옴\n",
    "        file_paths_batch = self.file_paths[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        targets_batch = self.targets[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "\n",
    "        # 배치사이즈, 위드, 하이트, 채널 (튜플로 만들어줘야댐)\n",
    "        results_batch = np.zeros((file_paths_batch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "        # 데이터 수만큼 반복\n",
    "        for i in range(file_paths_batch.shape[0]):\n",
    "            # 이미지 가져오기\n",
    "            image = cv2.cvtColor(cv2.imread(file_paths_batch[i]), cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "            # 어그먼테이션 있으면 어그먼 테이션 적용\n",
    "            if self.aug is not None:\n",
    "                self.aug(image=image)['image']\n",
    "\n",
    "            if self.preprocess is not None:\n",
    "                self.self.preprocess(image)\n",
    "\n",
    "            results_batch[i] = image\n",
    "\n",
    "        return results_batch, targets_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            # 이걸 먼저 하고 getitem을 하기 때뭉네 result로 안 넣고 file_paths로 넣음\n",
    "            # 그럼 get_items에는 이미 셔플이 되어있음\n",
    "            self.file_paths, self.targets = shuffle(self.file_paths, self.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10806e59-e185-4385-972e-3e7844fdd9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "# 별칭을 줄 수 있음... tf랑 torch랑 모두 같은 input이니까 써줘서 구분 해주기\n",
    "from tensorflow.keras.applications.xception import \n",
    "\n",
    "train_file_paths = train_df['file_paths'].values\n",
    "train_targets = train_df['targets'].values\n",
    "\n",
    "validation_file_paths = validation_df['file_paths'].values\n",
    "validation_targets = validation_df['targets'].values\n",
    "\n",
    "test_file_paths = test_df['file_paths'].values\n",
    "test_targets = test_df['targets'].values\n",
    "\n",
    "aug = A.Compose([\n",
    "    A.ShiftScaleRotate(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0, p=0.5)\n",
    "])\n",
    "\n",
    "train_dataset = Dataset(train_file_paths, train_targets, batch_size=BATCH_SIZE, aug=aug, preprocess=xception_preprocess_input, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870dee23-d187-4c18-b624-5dd340f66702",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model\n",
    "모바일넷 작은 장치에서 성능을 끌어올릴 수 있는 모델..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0050aef-917f-4eeb-a40f-64b69cad0187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e627d-574b-461f-af48-3425994e6dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbff434-56a4-4a09-9d7b-a1e240883655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745dc68-b8ca-4e34-8cc3-edae7ce5598b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c4c1c5-36da-4418-8132-9581671653dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10acbedb-6984-49b7-a098-f8e2e7e57f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ff903-f066-4533-9059-21ebb3e74ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00681be-f070-4800-816d-a2dc68000df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f75ef0-9deb-46a8-a59a-902dcde90f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
