{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae781c2-0156-4404-89d0-1c55c524f4c4",
   "metadata": {},
   "source": [
    "### Sequence\n",
    "동물 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8842a85-78cb-4611-9b2a-20ae13ce1938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26179 images belonging to 10 classes.\n",
      "{'butterfly': 0, 'cat': 1, 'chicken': 2, 'cow': 3, 'dog': 4, 'elephant': 5, 'horse': 6, 'sheep': 7, 'spider': 8, 'squirrel': 9}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 이미지가 저장되어 있는 경로 지정\n",
    "root = './datasets/animals/original/'\n",
    "\n",
    "# 이미지 전처리 객체 생성\n",
    "# 이미지의 픽셀 값을 0에서 255 사이에서 0에서 1 사이의 값으로 조정\n",
    "idg = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 이미지 전처리\n",
    "# 디렉토리에서 이미지를 가져와 배치로 변환\n",
    "generator = idg.flow_from_directory(root, target_size=(64, 64), batch_size=32, class_mode='categorical')\n",
    "# 각 클랙스의 이름과 인덱스 출력\n",
    "print(generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c83520e-7156-4799-bc43-6405a9bfcb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'butterfly',\n",
       " 1: 'cat',\n",
       " 2: 'chicken',\n",
       " 3: 'cow',\n",
       " 4: 'dog',\n",
       " 5: 'elephant',\n",
       " 6: 'horse',\n",
       " 7: 'sheep',\n",
       " 8: 'spider',\n",
       " 9: 'squirrel'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 타겟의 타겟 이름을 담기 위해 key와 value의 순서 변경하여 타겟의 고유값을 저장\n",
    "target_name = {v: k for k, v in generator.class_indices.items()}\n",
    "target_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9075e3ad-8014-4d30-a75d-f483559bd270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 타겟의 이름 담을 초기 list 선언\n",
    "target_names = []\n",
    "# 각 타겟의 인덱스를 확인하여 인덱스에 맞는 타겟 이름을 담아주기\n",
    "for target in generator.classes:\n",
    "    target_names.append(target_name[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9625888-c379-4aac-93f0-438ec523ca37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_paths</th>\n",
       "      <th>target_names</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./datasets/animals/original/butterfly/butterfl...</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./datasets/animals/original/butterfly/butterfl...</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./datasets/animals/original/butterfly/butterfl...</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./datasets/animals/original/butterfly/butterfl...</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./datasets/animals/original/butterfly/butterfl...</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26174</th>\n",
       "      <td>./datasets/animals/original/squirrel/squirrel9...</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26175</th>\n",
       "      <td>./datasets/animals/original/squirrel/squirrel9...</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26176</th>\n",
       "      <td>./datasets/animals/original/squirrel/squirrel9...</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26177</th>\n",
       "      <td>./datasets/animals/original/squirrel/squirrel9...</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26178</th>\n",
       "      <td>./datasets/animals/original/squirrel/squirrel9...</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26179 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_paths target_names  targets\n",
       "0      ./datasets/animals/original/butterfly/butterfl...    butterfly        0\n",
       "1      ./datasets/animals/original/butterfly/butterfl...    butterfly        0\n",
       "2      ./datasets/animals/original/butterfly/butterfl...    butterfly        0\n",
       "3      ./datasets/animals/original/butterfly/butterfl...    butterfly        0\n",
       "4      ./datasets/animals/original/butterfly/butterfl...    butterfly        0\n",
       "...                                                  ...          ...      ...\n",
       "26174  ./datasets/animals/original/squirrel/squirrel9...     squirrel        9\n",
       "26175  ./datasets/animals/original/squirrel/squirrel9...     squirrel        9\n",
       "26176  ./datasets/animals/original/squirrel/squirrel9...     squirrel        9\n",
       "26177  ./datasets/animals/original/squirrel/squirrel9...     squirrel        9\n",
       "26178  ./datasets/animals/original/squirrel/squirrel9...     squirrel        9\n",
       "\n",
       "[26179 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로와 타겟값을 가지고 새로운 데이터 프레임 생성\n",
    "animal_df = pd.DataFrame({'file_paths': generator.filepaths, 'target_names': target_names, 'targets': generator.classes})\n",
    "# 경로 중 \\\\(역슬래시)로 되어 있는 부분을 /(슬래시)로 변경 \n",
    "animal_df.file_paths = animal_df.file_paths.apply(lambda file_path: file_path.replace('\\\\', '/'))\n",
    "animal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44defb0b-9748-41fb-b3ca-eb4e62eaee4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets\n",
      "4    3890\n",
      "8    3857\n",
      "2    2478\n",
      "6    2098\n",
      "0    1690\n",
      "3    1493\n",
      "9    1490\n",
      "7    1456\n",
      "1    1334\n",
      "5    1157\n",
      "Name: count, dtype: int64\n",
      "targets\n",
      "4    973\n",
      "8    964\n",
      "2    620\n",
      "6    525\n",
      "0    422\n",
      "3    373\n",
      "9    372\n",
      "7    364\n",
      "1    334\n",
      "5    289\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 세트 분리\n",
    "train_images, test_images, train_targets, test_targets = \\\n",
    "train_test_split(animal_df.file_paths, \n",
    "                 animal_df.targets, \n",
    "                 stratify=animal_df.targets, \n",
    "                 test_size=0.2, random_state=124)\n",
    "\n",
    "# 타겟 비중 확인\n",
    "print(train_targets.value_counts())\n",
    "print(test_targets.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "923ec394-622a-4507-ad5b-0ce684bf11b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets\n",
      "4    3112\n",
      "8    3086\n",
      "2    1982\n",
      "6    1678\n",
      "0    1352\n",
      "3    1194\n",
      "9    1192\n",
      "7    1165\n",
      "1    1067\n",
      "5     926\n",
      "Name: count, dtype: int64\n",
      "targets\n",
      "4    778\n",
      "8    771\n",
      "2    496\n",
      "6    420\n",
      "0    338\n",
      "3    299\n",
      "9    298\n",
      "7    291\n",
      "1    267\n",
      "5    231\n",
      "Name: count, dtype: int64\n",
      "targets\n",
      "4    973\n",
      "8    964\n",
      "2    620\n",
      "6    525\n",
      "0    422\n",
      "3    373\n",
      "9    372\n",
      "7    364\n",
      "1    334\n",
      "5    289\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 검증용 데이터 세트 분리\n",
    "train_images, validation_images, train_targets, validation_targets = \\\n",
    "train_test_split(train_images, \n",
    "                 train_targets, \n",
    "                 stratify=train_targets, \n",
    "                 test_size=0.2, random_state=124)\n",
    "\n",
    "# 타겟 비중 확인\n",
    "print(train_targets.value_counts())\n",
    "print(validation_targets.value_counts())\n",
    "print(test_targets.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d1ede6-32b1-4d13-9541-321071e8fd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16754, 3)\n",
      "(4189, 3)\n",
      "(5236, 3)\n"
     ]
    }
   ],
   "source": [
    "# 인덱스 번호를 대조하여 각 데이터 프레임 나누기\n",
    "train_df = animal_df.iloc[train_images.index].reset_index(drop=True)\n",
    "validation_df = animal_df.iloc[validation_images.index].reset_index(drop=True)\n",
    "test_df = animal_df.iloc[test_images.index].reset_index(drop=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(validation_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e218b7-5d9b-45bd-8d54-be385539f7ea",
   "metadata": {},
   "source": [
    "시퀀스 api는 상속 받아서 내가 재저응 ㅣ\n",
    "데이터세트 객체를"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8394032f-6fbb-49fd-94e2-8d76074c200c",
   "metadata": {},
   "source": [
    "#### Step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "877bbc16-680b-4869-bf58-e2993b9e9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "\n",
    "# 이미지 사이즈 및 배치 사이즈\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 데이터 세트 생성 class 정의\n",
    "# Sequence 클래스 상속하고 있어 데이터를 미니배치를 통해 효율적으로 처리\n",
    "# epoch 한번 당 새로운 데이터 세트 생성\n",
    "class Dataset(Sequence):\n",
    "    # 클래스의 초기화\n",
    "    # 경로, 타겟, 배치 크기, albumentations 객체, 셔플 여부를 인자로 받음\n",
    "    def __init__(self, file_paths, targets, batch_size=BATCH_SIZE, aug=None, shuffle=False):\n",
    "        self.file_paths = file_paths\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.aug = aug\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # shuffle True 시 진행:\n",
    "        if self.shuffle:\n",
    "            # epoch 끝날 때마다 호출\n",
    "            # 해당 함수 호출 시 메모리 이슈가 발생하므로 직접 해제해야 함\n",
    "            self.on_epoch_end()\n",
    "\n",
    "    # 전체 데이터 세트 크기 반환\n",
    "    # __len__()는 전체 데이터 건수에서 batch_size 단위로 나눈 데이터 수\n",
    "    # 예를 들어, 1000개의 데이터를 30 batch_size로 설정하면, 1 batch당 33.33..개이다.\n",
    "    # 이 때, 소수점은 무조건 올려서 33 + 1 = 34개로 설정한다. (ceil 사용하여 올리기)\n",
    "    def __len__(self):\n",
    "        # 하나의 배치 사이즈에 필요한 데이터 개수 리턴\n",
    "        return int(np.ceil(len(self.targets) / self.batch_size))\n",
    "\n",
    "    # 주어진 인덱스에 해당하는 배치 반환\n",
    "    # batch_size 단위로 이미지 배열과 타켓 데이터들을 가져온 뒤 변환한 값을 리턴한다. (preprocessing)\n",
    "    # index: 몇번째 배치인지 인덱스로 나타냄\n",
    "    def __getitem__(self, index):\n",
    "        # 파일 경로와 타겟 데이터를 배치 크기만큼 자르고, 이미지를 불러와 처리한 후 배치로 반환\n",
    "        # 시작, 끝 인덱스를 정확하게 가져올 수 있다.\n",
    "        # 예를 들어, 배치사이즈 60개라 가정하면, 0부터 59까지 인덱스를 가져오는 것\n",
    "        # 인덱스 0 * 60 =0, (0 + 1) * 60 = 60\n",
    "        # 즉, [0, 60] 이 되는데 마지막 숫자는 반환하지 않으므로 0부터 59까지 인덱스 반환함\n",
    "        file_paths_batch = self.file_paths[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        targets_batch = self.targets[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "\n",
    "        # 데이터 배치 저장\n",
    "        # 배치 크기, 높이, 너비, 채널 수 (tuple로 받아야 한다.)\n",
    "        results_batch = np.zeros((file_paths_batch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "        # 데이터 수만큼 반복\n",
    "        for i in range(file_paths_batch.shape[0]):\n",
    "            # RGB로 색상 형식을 변환하여 이미지 가져오기\n",
    "            image = cv2.cvtColor(cv2.imread(file_paths_batch[i]), cv2.COLOR_BGR2RGB)\n",
    "            # 이미지 크기 조정\n",
    "            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "            # albumentations이 있다면:\n",
    "            if self.aug is not None:\n",
    "                # Augmentor 객체로 이미지 변환\n",
    "                image = self.aug(image=image)['image']\n",
    "\n",
    "            # 결과 배치에 이미지를 저장\n",
    "            results_batch[i] = image\n",
    "\n",
    "        # 결과 배치와 타겟 배치를 반환\n",
    "        return results_batch, targets_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # shuffle 옵션이 켜져있다면, 데이터를 섞기\n",
    "        if self.shuffle:\n",
    "            # on_epoch_end 먼저 진행 후 __getitem__을 하기 때문에\n",
    "            # results_batch 넣지 않고 self.file_paths를 받기 (__getitem__는 이미 shuffle 상태)\n",
    "            self.file_paths, self.targets = shuffle(self.file_paths, self.targets)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15670836-e0e7-4596-a9bf-f90f1730abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "# 훈련용 데이터 경로 담기\n",
    "train_file_paths = train_df['file_paths'].values\n",
    "# 훈련용 데이터 타겟 담기\n",
    "train_targets = train_df['targets'].values\n",
    "\n",
    "# 이미지 변환 (증강)\n",
    "aug = A.Compose([\n",
    "    # 크기 조정 및 회전\n",
    "    A.ShiftScaleRotate(p=0.5),\n",
    "    # 좌우 반전\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    # 밝기 및 대비 변경\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0, p=0.5)\n",
    "])\n",
    "\n",
    "# Dataset class로 객체 생성\n",
    "dataset = Dataset(train_file_paths, train_targets, batch_size=BATCH_SIZE, aug=aug, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade5e22-d13b-4295-a234-e9225c68be22",
   "metadata": {},
   "source": [
    "#### Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907325e-ea3e-4b35-95ae-66ec9db4b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "\n",
    "# 이미지 사이즈 및 배치 사이즈\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 데이터 세트 생성 class 정의\n",
    "class Dataset(Sequence):\n",
    "    # 클래스의 초기화\n",
    "    # 경로, 타겟, 배치 크기, albumentations 객체, 전처리 하마, 셔플 여부를 인자로 받음\n",
    "    def __init__(self, file_paths, targets, batch_size=BATCH_SIZE, aug=None, preprocess=None, shuffle=False):\n",
    "        self.file_paths = file_paths\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.aug = aug\n",
    "        self.preprocess = preprocess\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # shuffle True 시 진행:\n",
    "        if self.shuffle:\n",
    "            # epoch 끝날 때마다 호출\n",
    "            self.on_epoch_end()\n",
    "\n",
    "    # 전체 데이터 세트 크기 반환\n",
    "    def __len__(self):\n",
    "        # 하나의 배치 사이즈에 필요한 데이터 개수 리턴\n",
    "        return int(np.ceil(len(self.targets) / self.batch_size))\n",
    "\n",
    "    # 주어진 인덱스에 해당하는 배치 반환\n",
    "    def __getitem__(self, index):\n",
    "        # 파일 경로와 타겟 데이터를 배치 크기만큼 자르고, 이미지를 불러와 처리한 후 배치로 반환\n",
    "        file_paths_batch = self.file_paths[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        targets_batch = self.targets[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "\n",
    "        # 데이터 배치 저장\n",
    "        results_batch = np.zeros((file_paths_batch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "        # 데이터 수만큼 반복\n",
    "        for i in range(file_paths_batch.shape[0]):\n",
    "            # RGB로 색상 형식을 변환하여 이미지 가져오기\n",
    "            image = cv2.cvtColor(cv2.imread(file_paths_batch[i]), cv2.COLOR_BGR2RGB)\n",
    "            # 이미지 크기 조정\n",
    "            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "            # albumentations이 있다면:\n",
    "            if self.aug is not None:\n",
    "                # Augmentor 객체로 이미지 변환\n",
    "                image = self.aug(image=image)['image']\n",
    "\n",
    "            # 전처리 함수가 있다면:\n",
    "            if self.preprocess is not None:\n",
    "                # 이미지 전처리 진행\n",
    "                image = self.preprocess(image)\n",
    "\n",
    "            # 결과 배치에 이미지를 저장\n",
    "            results_batch[i] = image\n",
    "\n",
    "        # 결과 배치와 타겟 배치를 반환\n",
    "        return results_batch, targets_batch\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        # shuffle 옵션이 켜져있다면, 데이터를 섞기\n",
    "        if self.shuffle:\n",
    "            # epoch 끝날 때마다 데이터 섞기\n",
    "            self.file_paths, self.targets = shuffle(self.file_paths, self.targets)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10806e59-e185-4385-972e-3e7844fdd9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "# preprocess_input 함수에 별칭 지정\n",
    "# tensorflow와 torch 모두 같은 이름의 함수를 받기 때문에 별칭으로 구분\n",
    "from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess_input\n",
    "\n",
    "# 데이터 경로 담기\n",
    "train_file_paths = train_df['file_paths'].values\n",
    "# 데이터 타겟 담기\n",
    "# get_dummies를 통해 원-핫 인코딩 진행\n",
    "train_targets = pd.get_dummies(train_df['targets']).values # CategoricalCrossEntropy\n",
    "# train_targets = train_df['targets'].values # SparseCategoricalCrossEntropy\n",
    "\n",
    "# 데이터 경로 담기\n",
    "validation_file_paths = validation_df['file_paths'].values\n",
    "# 데이터 타겟 담기\n",
    "# get_dummies를 통해 원-핫 인코딩 진행\n",
    "validation_targets = pd.get_dummies(validation_df['targets']).values # CategoricalCrossEntropy\n",
    "# validation_targets = validation_df['targets'].values # SparseCategoricalCrossEntropy\n",
    "\n",
    "# 데이터 경로 담기\n",
    "test_file_paths = test_df['file_paths'].values\n",
    "# 데이터 타겟 담기\n",
    "# get_dummies를 통해 원-핫 인코딩 진행\n",
    "test_targets = pd.get_dummies(test_df['targets']).values # CategoricalCrossEntropy\n",
    "# test_targets = test_df['targets'].values # SparseCategoricalCrossEntropy\n",
    "\n",
    "# 이미지 변환 (증강)\n",
    "aug = A.Compose([\n",
    "    # 크기 조정 및 회전\n",
    "    A.ShiftScaleRotate(p=0.5),\n",
    "    # 좌우 반전\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    # 밝기 및 대비 변경\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0, p=0.5)\n",
    "])\n",
    "\n",
    "# Dataset class로 객체 생성\n",
    "train_dataset = Dataset(train_file_paths, \n",
    "                        train_targets, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        aug=aug, \n",
    "                        preprocess=xception_preprocess_input, \n",
    "                        shuffle=True)\n",
    "\n",
    "validation_dataset = Dataset(validation_file_paths, \n",
    "                        validation_targets, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        preprocess=xception_preprocess_input)\n",
    "\n",
    "test_dataset = Dataset(test_file_paths, \n",
    "                        test_targets, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        preprocess=xception_preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0050aef-917f-4eeb-a40f-64b69cad0187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications import MobileNetV2 # 작은 장치에서도 성능을 끌어올릴 수 있는 모델\n",
    "\n",
    "# 모델 생성 함수 선언\n",
    "# model_name: 사전 훈련 모델 이름, verbose: 모델 요약 출력 여부\n",
    "def create_model(model_name='vgg16', verbose=False):\n",
    "    # Input layer: 이미지 크기와 채널 수를 지정\n",
    "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    # VGG16 모델 선택\n",
    "    if model_name == 'vgg16':\n",
    "        model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    # ResNet50V2 모델 선택\n",
    "    elif model_name == 'resnet50': # ResNet50, 74.9% ; ResNet50V2, 76.0%\n",
    "        model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    # Xception 모델 선택\n",
    "    elif model_name == 'xception': # Inception을 기초로 한 모델\n",
    "        model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    # MobileNetV2 모델 선택\n",
    "    elif model_name == 'mobilenet':\n",
    "        model = MobileNetV2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "\n",
    "    # output layer: 모델 출력 층 \n",
    "    x = model.output\n",
    "\n",
    "    # 분류기\n",
    "    # GlobalAveragePooling2D: 글로벌 평균 풀링 층을 추가하여 특성 맵의 공간 차원 축소\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # hidden layer: VGG16 모델 선택을 선택하지 않았다면 dropout 미진행\n",
    "    if model_name != 'vgg16':\n",
    "        x = Dropout(rate=0.5)(x)\n",
    "\n",
    "    # hidden layer: 50개의 뉴런과 ReLU 활성화 함수 사용\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "\n",
    "    # hidden layer: VGG16 모델 선택을 선택하지 않았다면 dropout 미진행\n",
    "    if model_name != 'vgg16':\n",
    "        x = Dropout(rate=0.5)(x)\n",
    "\n",
    "    # output layer: 10개의 뉴런과 소프트맥스 활성화 함수를 사용하여 클래스 확률 출력\n",
    "    output = Dense(10, activation='softmax', name='output')(x)\n",
    "\n",
    "    # 모델 생성: 입력과 출력을 지정하여 모델 정의\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "    # verbose가 True인 경우 모델 요약 출력\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e627d-574b-461f-af48-3425994e6dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "\n",
    "# 모델 생성 함수를 사용하여 모델 생성\n",
    "model = create_model(model_name='mobilenet', verbose=True)\n",
    "\n",
    "# 모델 컴파일: 학습 프로세스 설정\n",
    "# optimizer: 최적화 알고리즘, loss: 손실함수, metrics: 성능지표\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "# # 모델 생성 시 get_dummies로 원-핫 인코딩을 진행하지 않았다면 아래 코드 사용\n",
    "# model.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbff434-56a4-4a09-9d7b-a1e240883655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# # weights 저장\n",
    "# mcp_cb = ModelCheckpoint(\n",
    "#     filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "#     monitor='val_loss',\n",
    "#     save_best_only=False,\n",
    "#     save_weights_only=True,\n",
    "#     mode='min'\n",
    "# )\n",
    "\n",
    "# 일정 기간 동안 성능이 개선되지 않을 시 학습률 동적으로 감소\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# 일정 기간 동안 성능이 개선되지 않을 시 학습 조기 중단\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=4,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db2751-26ce-4296-b330-e90a0b5e699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# 메모리 해제 함수\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745dc68-b8ca-4e34-8cc3-edae7ce5598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복횟수 지정\n",
    "# 대문자로 상수를 표기하면 다른 부분에서 변경되지 않는다는 것을 의미\n",
    "N_EPOCHS = 10\n",
    "\n",
    "# 훈련\n",
    "history = model.fit(train_dataset,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=N_EPOCHS, \n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=[rlr_cb, ely_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c4c1c5-36da-4418-8132-9581671653dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "model.evaluate(test_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10acbedb-6984-49b7-a098-f8e2e7e57f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습과정 지표를 그래프화\n",
    "def show_history(history):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.yticks(np.arange(0, 1, 0.05))\n",
    "    plt.plot(history.history['acc'], label='train')\n",
    "    plt.plot(history.history['val_acc'], label='validation')\n",
    "    plt.legend()\n",
    "    \n",
    "show_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
